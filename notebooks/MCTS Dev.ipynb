{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from lib.cube import Cube\n",
    "from lib.solver import CubeSolver\n",
    "from lib.models import CNN\n",
    "\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "\n",
    "config['model_params'] = {'embed_dim':100,\n",
    "                          'num_filters':50,\n",
    "                          'num_conv_layers':3,\n",
    "                          'kernel_size':2,\n",
    "                          'regularization_constant':.5,\n",
    "                          'num_dense_layers':3,\n",
    "                           'dense_activation':'elu'}\n",
    "#global vars\n",
    "solver = CubeSolver()\n",
    "solver.model = CNN(**config['model_params'])\n",
    "solver.load_model_weights('../models/base_model_v2_20190404001914/weights')\n",
    "\n",
    "c = 0.1 #exploration hyper parameter\n",
    "v = 0.1 # virtual loss hyper parameter\n",
    "sovled_cube = Cube() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node(object):\n",
    "    def __init__(self,state, parent=None):\n",
    "        self.parent=parent\n",
    "        self.children=[]\n",
    "        self.state=copy.deepcopy(state)\n",
    "        self.action_taken_string=None\n",
    "        self.N = self._init_N()\n",
    "        self.W = self._init_W()\n",
    "        self.L = self._init_L()\n",
    "        self.P = self._init_P()\n",
    "        \n",
    "    def _init_N(self):\n",
    "        N = dict(zip(cube_moves,[0]*len(cube_moves)))\n",
    "        return N\n",
    "    def _init_W(self):\n",
    "        W = dict(zip(cube_moves,[0]*len(cube_moves)))\n",
    "        return W\n",
    "    \n",
    "    def _init_L(self):\n",
    "        L = dict(zip(cube_moves,[0]*len(cube_moves)))\n",
    "        return L\n",
    "    \n",
    "    def _init_P(self):\n",
    "        node_state = copy.deepcopy(self.state)\n",
    "        node_state = tf.convert_to_tensor(node_state)\n",
    "        node_state = tf.expand_dims(node_state, 0)\n",
    "        action_probs = tf.keras.activations.softmax(solver.model(node_state)).numpy()[0]\n",
    "        P = dict(zip(cube_moves,action_probs))\n",
    "        return P\n",
    "    \n",
    "    def get_Q_st(self):\n",
    "        W_st = np.array(list(self.W.values()))\n",
    "        L_st = np.array(list(self.L.values()))\n",
    "        Q_st = W_st - L_st\n",
    "        return Q_st\n",
    "    \n",
    "    def get_U_st(self):\n",
    "        P_st = np.array(list(self.P.values()))\n",
    "        N_st = np.array(list(self.N.values()))\n",
    "        U_st = c*P_st*np.sqrt(N_st.sum()) / (1 + N_st)\n",
    "        return U_st\n",
    "    \n",
    "    def update_memory(self, q_current_state):\n",
    "        self.W[self.action_taken_string] = max(self.W[self.action_taken_string],q_current_state)\n",
    "        self.N[self.action_taken_string] += 1\n",
    "#         self.L[self.action_taken_string] -= v\n",
    "        self.action_taken_string=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_rate = 0\n",
    "c = .1 #exploration hyper parameter\n",
    "v = .5 # virtual loss hyper parameter\n",
    "for trial in range(10):\n",
    "\n",
    "\n",
    "    cube = Cube() #global var\n",
    "    cube.shuffle(num_shuffles=5,verbose=False)\\\n",
    "#     print(\"down_p\")\n",
    "#     cube.down_p()\n",
    "#     print(\"right\")\n",
    "#     cube.right()\n",
    "#     print(\"front\")\n",
    "#     cube.front()\n",
    "#     print('-----------')\n",
    "\n",
    "\n",
    "    cube_moves=[] #global var\n",
    "    for move in cube.func_list:\n",
    "        cube_moves.append(str(move).split()[2].split('.')[1])\n",
    "    root = Node(cube.state)\n",
    "\n",
    "\n",
    "    for i in range(1000): #Should this be time based?\n",
    "        #selection\n",
    "        current_node = root\n",
    "        while current_node.children: #while not leaf node\n",
    "            Q_st = current_node.get_Q_st()\n",
    "            U_st = current_node.get_U_st()\n",
    "            A_st = np.argmax(U_st + Q_st)\n",
    "            A_st_string = cube_moves[A_st]\n",
    "#             print(f\"Enter Selection: {A_st_string}\")\n",
    "\n",
    "\n",
    "            #update loss\n",
    "            current_node.L[A_st_string] += v\n",
    "            #save action taken\n",
    "            current_node.action_taken_string=A_st_string\n",
    "            #move to next node\n",
    "            current_node = current_node.children[A_st]\n",
    "\n",
    "\n",
    "        #check for termination\n",
    "        if (current_node.state == sovled_cube.state).all():\n",
    "#             print(\"Cube is solved\")\n",
    "            solve_rate+=1\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        #expansion\n",
    "#         print(\"Expansion\")\n",
    "        for move in cube.func_list:\n",
    "            cube.set_state(current_node.state)\n",
    "            move()\n",
    "            move_name = str(move).split()[2].split('.')[1] #could be inefficient\n",
    "            new_state = Node(cube.state, parent=current_node)\n",
    "            current_node.children.append(new_state)\n",
    "\n",
    "        #simulation ?\n",
    "#         print(\"Simulation\")\n",
    "\n",
    "        current_state = copy.deepcopy(current_node.state)\n",
    "        current_state = tf.convert_to_tensor(current_state)\n",
    "        current_state = tf.expand_dims(current_state, 0)\n",
    "\n",
    "        a_current_state = solver.model(current_state).numpy()[0].argmax()\n",
    "        current_node.action_taken_string=cube_moves[a_current_state]\n",
    "\n",
    "        q_current_state = solver.model(current_state).numpy()[0].max() #are q and v the same?\n",
    "\n",
    "\n",
    "        #backpropagation\n",
    "#         print(\"Backpropagation\")\n",
    "        current_node.update_memory(q_current_state)\n",
    "        while current_node.parent is not None:\n",
    "#             print(\"Propagating\")\n",
    "            current_node = current_node.parent\n",
    "            current_node.update_memory(q_current_state)\n",
    "\n",
    "\n",
    "#         if i == 99:\n",
    "#             print(\"Time Out\")\n",
    "#         else:\n",
    "#             print('--------------')\n",
    "solve_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n",
      "tf.Tensor(\n",
      "[[ 0.99546456  0.9990916   0.9998145  -0.9992658  -0.9998772  -0.99897933\n",
      "  -0.99988675  0.99983263  0.9998877   0.99891365]\n",
      " [-0.9954648  -0.9990915  -0.99981445  0.9992658   0.9998771   0.9989795\n",
      "   0.99988663 -0.99983263 -0.9998877  -0.99891394]], shape=(2, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2.0861625e-08, 0.9991022)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = tf.keras.layers.BatchNormalization(1)\n",
    "\n",
    "x = tf.constant([[3.,7.,2.,4.],[.1,.7,.8,.9]])\n",
    "\n",
    "fc1 = tf.keras.layers.Dense(10)\n",
    "print(fc1(x).shape)\n",
    "out = bn(fc1(x),training=True)\n",
    "print(out)\n",
    "out.numpy().mean(),out.numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3 - 1.55) / 1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(.1 - 1.55) / 1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.55"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3+.1) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.45"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([3,.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = tf.keras.Sequential()\n",
    "fc_layer = tf.keras.layers.Dense(2,activation=None)\n",
    "batch_norm = tf.keras.layers.BatchNormalization(axis=0)\n",
    "activation = tf.keras.layers.ELU()\n",
    "\n",
    "fc.add(fc_layer)\n",
    "fc.add(batch_norm)\n",
    "fc.add(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.99957955 -0.9800308 ]\n",
      " [-0.15352827 -0.575464  ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(fc(x, training=False))\n",
    "print(fc(tf.expand_dims(tf.constant([3.,7.,2.,4.]),0), training= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 2, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.expand_dims(tf.constant([[3.,7.],[.1,.7]]),0)\n",
    "x = tf.expand_dims(x,0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 3)\n",
      "(1, 3, 3, 3, 100)\n",
      "(1, 2, 2, 2, 50)\n",
      "(2, 2, 2)\n",
      "-0.0093600545 0.023751186\n",
      "-1.4901161e-08 0.6005517\n"
     ]
    }
   ],
   "source": [
    "embedding = tf.keras.layers.Embedding(27, 100)\n",
    "cnn_layer = tf.keras.layers.Conv3D(filters=50,\n",
    "                                   kernel_size=2,\n",
    "                                   data_format='channels_last',\n",
    "                                   padding = 'valid')\n",
    "\n",
    "bn = tf.keras.layers.BatchNormalization(axis = -1)\n",
    "\n",
    "print(current_state.shape)\n",
    "print(embedding(current_state).shape)\n",
    "print(cnn_layer(embedding(current_state)).shape)\n",
    "out = cnn_layer(embedding(current_state))\n",
    "normed_out = bn(out, training= True)\n",
    "fm = 19\n",
    "print(out.numpy()[0,:,:,:,fm].shape)\n",
    "print(out.numpy()[0,:,:,:,fm].mean(), out.numpy()[:,:,:,:,fm].std())\n",
    "print(normed_out.numpy()[0,:,:,:,fm].mean(), normed_out.numpy()[0,:,:,:,fm].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = tf.keras.layers.Flatten()\n",
    "#         self.fc = self._build_fc_layers(num_dense_layers,\n",
    "#                                         activation=self.dense_activation)\n",
    "#         self.output_layer = tf.keras.layers.Dense(12,\n",
    "#                                             activation=self.dense_activation,\n",
    "#                                             kernel_regularizer=tf.keras.regularizers.l2(l=self.rc),\n",
    "#                                             bias_regularizer=tf.keras.regularizers.l2(l=self.rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(out).shape\n",
    "output_layer = tf.keras.layers.Dense(12)\n",
    "print(flatten(out).shape)\n",
    "output_layer(flatten(out)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.embed_dim = embed_dim\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.rc = regularization_constant\n",
    "        self.dense_activation = dense_activation\n",
    "        self.embedding = tf.keras.layers.Embedding(27, self.embed_dim)\n",
    "        self.cnn = self._build_conv_layers(num_conv_layers)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = self._build_fc_layers(num_dense_layers)\n",
    "        self.output_layer = tf.keras.layers.Dense(12,\n",
    "                                            activation=self.dense_activation,\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(l=self.rc),\n",
    "                                            bias_regularizer=tf.keras.regularizers.l2(l=self.rc))\n",
    "\n",
    "    def _build_conv_layers(self, num_conv_layers):\n",
    "        '''\n",
    "        helper function for init\n",
    "        '''\n",
    "        cnn = tf.keras.Sequential()\n",
    "        for i in range(num_conv_layers):\n",
    "            if i == 0:\n",
    "                padding = 'valid'\n",
    "            else:\n",
    "                padding = 'same'\n",
    "            cnn_layer = tf.keras.layers.Conv3D(filters=self.num_filters,\n",
    "                                               kernel_size=self.kernel_size,\n",
    "                                               data_format='channels_last',\n",
    "                                               padding = padding)\n",
    "            cnn.add(cnn_layer)\n",
    "        return cnn\n",
    "\n",
    "\n",
    "    def _build_fc_layers(self, num_dense_layers):\n",
    "        '''\n",
    "        helper function for init\n",
    "        '''\n",
    "        fc = tf.keras.Sequential()\n",
    "        for i in range(num_dense_layers):\n",
    "            fc_layer = tf.keras.layers.Dense(50,\n",
    "                                             kernel_regularizer=tf.keras.regularizers.l2(l=self.rc),\n",
    "                                             bias_regularizer=tf.keras.regularizers.l2(l=self.rc),\n",
    "                                             activation=self.dense_activation)\n",
    "            fc.add(fc_layer)\n",
    "        return fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_node = root\n",
    "while current_node.children: #while not leaf node\n",
    "    Q_st = current_node.get_Q_st()\n",
    "    U_st = current_node.get_U_st()\n",
    "    A_st = np.argmax(U_st + Q_st)\n",
    "    A_st_string = cube_moves[A_st]\n",
    "    print(A_st_string)\n",
    "    #update loss\n",
    "    current_node.L[A_st_string] += v\n",
    "    #move to next node\n",
    "    current_node = current_node.children[A_st]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_node.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_node.parent.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
